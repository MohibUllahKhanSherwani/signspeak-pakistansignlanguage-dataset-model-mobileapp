# SignSpeak Data Collection Module

[![Python Version](https://img.shields.io/badge/python-3.9%20%7C%203.10%20%7C%203.11-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15.0-orange.svg)](https://www.tensorflow.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

**SignSpeak** is a comprehensive machine learning pipeline for Pakistan Sign Language (PSL) recognition. This repository contains tools for data collection, model training, and real-time inference using MediaPipe landmark detection and LSTM neural networks.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [System Requirements](#system-requirements)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Advanced Usage](#advanced-usage)
- [Model Comparison](#model-comparison)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

SignSpeak is part of a larger Final Year Project (FYP) at COMSATS University Islamabad, Abbottabad Campus. This repository specifically handles the machine learning component:

- **Data Collection**: GUI-based tool for recording PSL sign sequences
- **Feature Extraction**: MediaPipe holistic landmark detection (pose + hands)
- **Model Training**: LSTM-based deep learning with optional data augmentation
- **Inference**: Real-time sign recognition with performance metrics

**Note**: This is the ML data collection and training module. The complete SignSpeak system includes a Flutter mobile app and FastAPI backend (developed separately).

---

## âœ¨ Features

### Data Collection
- âœ… Modern GUI for efficient data recording
- âœ… Pause/resume functionality for long sessions
- âœ… Real-time landmark visualization
- âœ… Progress tracking across multiple signs
- âœ… Keyboard shortcuts for streamlined workflow

### Model Training
- âœ… Baseline training (standard approach)
- âœ… Advanced training with data augmentation (3-5x dataset expansion)
- âœ… Automated model comparison and evaluation
- âœ… Early stopping and learning rate scheduling
- âœ… Model checkpointing (saves best model)

### Real-Time Inference
- âœ… Webcam-based sign recognition
- âœ… Model selection (baseline vs augmented)
- âœ… Live accuracy tracking
- âœ… Performance metrics (FPS, confidence scores)

### Data Augmentation
- âœ… Time warping (speed variations)
- âœ… Horizontal flipping (left/right hand swapping)
- âœ… Spatial transformations (scaling, translation, rotation)
- âœ… Gaussian noise injection
- âœ… Temporal cropping

---

## ğŸ’» System Requirements

### Minimum Requirements
- **Operating System**: Windows 10+, Ubuntu 20.04+, or macOS 10.15+
- **Python**: 3.9, 3.10, or 3.11 (3.11 recommended)
- **RAM**: 8 GB minimum
- **Storage**: 5 GB free space
- **Camera**: Webcam for data collection and inference

### Recommended Requirements
- **Python**: 3.11.9
- **RAM**: 16 GB
- **GPU**: NVIDIA GPU with CUDA support (optional, for faster training)

### Tested Configuration
```
OS: Windows 11
Python: 3.11.9
TensorFlow: 2.15.0
NumPy: 1.26.4
OpenCV: 4.9.0.80
MediaPipe: 0.10.9
```

---

## ğŸš€ Installation

### Step 1: Clone Repository

```bash
git clone <repository-url>
cd SignSpeak-DataCollection
```

### Step 2: Create Virtual Environment

**Windows (PowerShell)**:
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

**Windows (CMD)**:
```cmd
python -m venv venv
venv\Scripts\activate.bat
```

**Linux/macOS**:
```bash
python3 -m venv venv
source venv/bin/activate
```

> **Note**: If PowerShell gives an execution policy error:
> ```powershell
> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
> ```

### Step 3: Install Dependencies

```bash
# Upgrade pip
python -m pip install --upgrade pip

# Install all dependencies
pip install -r requirements.txt
```

### Step 4: Verify Installation

```bash
python -c "import tensorflow as tf; import cv2; import mediapipe as mp; print('âœ… All dependencies installed successfully')"
```

Expected output:
```
âœ… All dependencies installed successfully
```

---

## ğŸ“ Project Structure

```
SignSpeak-DataCollection/
â”œâ”€â”€ ml_pipeline_data_collection/    # Main ML workspace
â”‚   â”œâ”€â”€ MP_Data/                    # Collected landmark sequences (gitignored)
â”‚   â”œâ”€â”€ actions.txt                 # List of PSL signs to recognize
â”‚   â”œâ”€â”€ actions_config.py           # Configuration parameters
â”‚   â”œâ”€â”€ data_augmentation.py        # Augmentation algorithms
â”‚   â”œâ”€â”€ collect_data_gui.py         # Enhanced data collection GUI
â”‚   â”œâ”€â”€ train_model.py              # Baseline training script
â”‚   â”œâ”€â”€ train_model_with_augmentation.py  # Advanced training with augmentation
â”‚   â”œâ”€â”€ compare_models.py           # Automated model comparison
â”‚   â”œâ”€â”€ realtime_inference.py       # Basic inference script
â”‚   â”œâ”€â”€ realtime_inference_enhanced.py    # Enhanced inference with model selection
â”‚   â”œâ”€â”€ action_model.h5             # Trained model (after training)
â”‚   â”œâ”€â”€ label_encoder.pkl           # Label encoder (after training)
â”‚   â””â”€â”€ links_to_words.txt          # Reference links to PSL dictionary
â”œâ”€â”€ SRS/                            # Software Requirements Specification
â”‚   â””â”€â”€ srs.txt
â”œâ”€â”€ SDD/                            # Software Design Document
â”‚   â””â”€â”€ sdd.txt
â”œâ”€â”€ venv/                           # Virtual environment (gitignored)
â”œâ”€â”€ requirements.txt                # Pinned Python dependencies
â”œâ”€â”€ .gitignore                      # Git ignore rules
â””â”€â”€ README.md                       # This file
```

---

## ğŸ¬ Quick Start

### 1. Prepare Actions List

Create or edit `ml_pipeline_data_collection/actions.txt`:

```bash
cd ml_pipeline_data_collection
notepad actions.txt  # Windows
# OR
nano actions.txt     # Linux/macOS
```

Add PSL signs (one per line):
```
hello
thankyou
please
yes
no
```

### 2. Collect Data

```bash
python collect_data_gui.py
```

**GUI Controls**:
- Add/remove signs using buttons
- Select sign from dropdown
- Click "START COLLECTING" to begin
- Press **SPACE** to pause/resume
- Press **ESC** to stop

**Recommended**: Collect 50 sequences per sign for optimal results.

### 3. Train Model

**Option A: Baseline Model** (faster, no augmentation)
```bash
python train_model.py
```

**Option B: Augmented Model** (recommended, better accuracy)
```bash
python train_model_with_augmentation.py --augment
```

**Option C: Automated Comparison** (trains both and compares)
```bash
python compare_models.py
```

### 4. Test Model

```bash
# Test default model
python realtime_inference.py

# OR test with model selection
python realtime_inference_enhanced.py --augmented
```

---

## ğŸ”¬ Advanced Usage

### Data Augmentation

Augmentation effectively increases your dataset by 3-5x without additional data collection:

```bash
# 3x augmentation (recommended)
python train_model_with_augmentation.py --augment --augment-multiplier 3

# 5x augmentation (for very small datasets)
python train_model_with_augmentation.py --augment --augment-multiplier 5

# Custom epochs
python train_model_with_augmentation.py --augment --epochs 150
```

**Augmentation Techniques**:
- Time warping (0.8x-1.2x speed)
- Horizontal flipping (mirror + hand swapping)
- Spatial scaling (0.9x-1.1x)
- Spatial translation (Â±10%)
- Rotation (Â±15Â°)
- Gaussian noise (1% std)
- Temporal cropping (Â±10%)

### Configuration

Edit `ml_pipeline_data_collection/actions_config.py`:

```python
# Recording parameters
SEQUENCE_LENGTH = 30        # Frames per sequence
NUM_SEQUENCES = 50          # Sequences per sign
FRAME_WAIT_MS = 50          # Delay between frames (ms)

# Model parameters
BATCH_SIZE = 16
EPOCHS = 200
LEARNING_RATE = 0.001

# Inference parameters
PREDICTION_THRESHOLD = 0.5  # Minimum confidence
```

### Model Architecture

LSTM-based sequential model:
```
Input: (30 frames, 225 features)
â”œâ”€â”€ LSTM(64, return_sequences=True)
â”œâ”€â”€ LSTM(128, return_sequences=True)
â”œâ”€â”€ LSTM(64)
â”œâ”€â”€ Dense(64)
â”œâ”€â”€ Dense(32)
â””â”€â”€ Dense(num_classes, softmax)

Total params: ~500K
```

**Features**: 225 values per frame
- Pose: 33 landmarks Ã— 3 coords = 99
- Left hand: 21 landmarks Ã— 3 coords = 63
- Right hand: 21 landmarks Ã— 3 coords = 63

---

## ğŸ“Š Model Comparison

### Comparing Baseline vs Augmented

```bash
# Automated comparison (recommended)
python compare_models.py
```

**Output**:
```
MODEL COMPARISON REPORT
==================================================
Dataset:
  Baseline:  100 sequences
  Augmented: 300 sequences (3x)

Accuracy:
  Baseline  - Train: 95.5%, Test: 78.2%  (Gap: 17.3%)
  Augmented - Train: 93.8%, Test: 89.5%  (Gap: 4.3%)

ğŸ† RECOMMENDATION: USE AUGMENTED MODEL
   âœ… +11.3% better test accuracy
   âœ… Reduced overfitting by 13.0%
```

### Manual Testing

```bash
# Test baseline
python realtime_inference_enhanced.py --baseline
# Perform 20 predictions, mark as correct/wrong
# Note accuracy

# Test augmented
python realtime_inference_enhanced.py --augmented
# Perform same 20 predictions
# Compare accuracy
```

**Keyboard Controls During Testing**:
- **SPACE**: Mark prediction as correct âœ…
- **X**: Mark prediction as wrong âŒ
- **R**: Reset statistics
- **Q**: Quit

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### 1. Import Errors
**Problem**: `ModuleNotFoundError: No module named 'tensorflow'`

**Solution**:
```bash
# Ensure virtual environment is activated
# Look for (venv) in command prompt

# Windows
.\venv\Scripts\Activate.ps1

# Reinstall dependencies
pip install -r requirements.txt
```

#### 2. Camera Not Detected
**Problem**: "Camera error!" or black screen

**Solution**:
- Close other apps using camera (Zoom, Teams, etc.)
- Check Windows camera permissions: Settings â†’ Privacy â†’ Camera
- Try different camera index in code: `cv2.VideoCapture(1)`

#### 3. TensorFlow Warnings
**Warning**: `oneDNN custom operations are on...`

**This is normal** - It's an informational message, not an error. To suppress:
```bash
set TF_ENABLE_ONEDNN_OPTS=0  # Windows CMD
$env:TF_ENABLE_ONEDNN_OPTS=0  # PowerShell
export TF_ENABLE_ONEDNN_OPTS=0  # Linux/macOS
```

#### 4. Low Accuracy
**Problem**: Validation accuracy < 80%

**Solutions**:
- Collect more data (aim for 50+ sequences per sign)
- Use data augmentation (`--augment`)
- Ensure consistent signing across sequences
- Check lighting conditions during data collection

#### 5. Out of Memory (OOM)
**Problem**: Training crashes with OOM error

**Solutions**:
- Reduce `BATCH_SIZE` in `actions_config.py` (try 8 or 4)
- Reduce `EPOCHS` (try 100 instead of 200)
- Close other applications
- Consider using GPU if available

### GPU Acceleration (Optional)

If you have an NVIDIA GPU:

```bash
# Uninstall CPU version

 tensorflow
pip uninstall tensorflow

# Install GPU version
pip install tensorflow[and-cuda]==2.15.0
```

Verify GPU:
```python
import tensorflow as tf
print("GPU Available:", tf.config.list_physical_devices('GPU'))
```

---

## ğŸ“š Documentation

Additional guides available in `/brain/` artifacts:
- `project_summary.md` - Complete FYP project overview
- `gui_features_guide.md` - Detailed GUI documentation
- `augmentation_guide.md` - Data augmentation deep dive
- `testing_workflow.md` - Comprehensive testing guide
- `inference_comparison_guide.md` - Model comparison workflow

---

## ğŸ¤ Contributing

This is an academic FYP project. For issues or suggestions:

1. Check existing issues
2. Create a new issue with detailed description
3. Include error messages and system information

---

**Authors**:
- AbuZar Babar (CIIT/FA22-BSE-133/ATD)
- Mohib Ullah Khan Sherwani (CIIT/FA22-BSE-125/ATD)
- M. Abdullah Umar (CIIT/FA22-BSE-126/ATD)

**Supervisor**: Dr. Rab Nawaz Jadoon

---

## ğŸ™ Acknowledgments

- MediaPipe team for landmark detection library
- PSL Dictionary (psl.org.pk) for reference signs
- TensorFlow/Keras community

---

## ğŸ“ Support

For technical issues specific to this repository:
- Check [Troubleshooting](#troubleshooting) section
- Review documentation in `/brain/` artifacts
- Create an issue with detailed logs

---

**Version**: 1.0.0  
**Last Updated**: January 2026  
**Python**: 3.9+ (3.11 recommended)  
**Status**: Active Development
